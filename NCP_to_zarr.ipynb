{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6374e4db-8477-48bf-b4ef-6fb47e62ad9e",
   "metadata": {},
   "source": [
    "import required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd693b8-9016-458f-b2ad-b381ef5fc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import struct\n",
    "import json\n",
    "import zarr\n",
    "from ncplib.packets import decode_packet\n",
    "import xarray as xr\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2988ed1-b339-49c4-a9fd-692424f524b3",
   "metadata": {},
   "source": [
    "open the file and read into variable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4454d1-bedc-472c-9e95-3f7844c63f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i renamed the pbd2 file\n",
    "with open(\"RFEYE.ncp\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ad50c-c621-4141-93e5-612c08a4f99b",
   "metadata": {},
   "source": [
    "This is a function that gets the starts and stops of each ncp packet and saves them as list of tuples. Example: [(4, 26305), (26309, 52611)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacde86-9a1d-4c90-af0f-12c04b8f2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices(b):\n",
    "    pos = 0\n",
    "    slices=[]\n",
    "    while pos < len(b):\n",
    "        msg_len = struct.unpack('<L', b[pos+8:pos+12])[0]*4\n",
    "        slices.append((pos, pos+msg_len))\n",
    "        pos = pos+msg_len\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5bd29-fdc6-4996-805a-995e954baefb",
   "metadata": {},
   "source": [
    "Get the slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866fd11-09e5-46a9-8857-b2d7b3c8a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = get_slices(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a3914-cc29-42f5-8acf-9dd09abf3c41",
   "metadata": {},
   "source": [
    "converts the tuple returned by decode_packet to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58493d-c2f1-4ba6-9ede-22bdfb4deea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tup_to_dict(*args):\n",
    "    packet_type, packet_id, timestamp, source_id, fields = args\n",
    "    packet_dict = {'packet_id': packet_id, 'timestamp': timestamp, 'source_id': int(binascii.hexlify(source_id))}\n",
    "    field_dict = {}\n",
    "    for arg in fields:\n",
    "        data_dict = {}\n",
    "        name, _id, data = arg\n",
    "        for field in data:\n",
    "            key, value = field\n",
    "            data_dict[key]=value\n",
    "        field_dict[name]=data_dict\n",
    "        packet_dict['fields'] = field_dict\n",
    "    return packet_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbfa0db-9daa-4c98-852e-5d8b91ff9fcf",
   "metadata": {},
   "source": [
    "Function to read dictionary to xarray DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f35514-dfcd-48a6-a2ad-b3c36b348b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xr(_dict):\n",
    "    source_id = _dict['source_id']\n",
    "    rlev = _dict['fields']['SWEP']['RLEV']\n",
    "    pdat = np.array(_dict['fields']['SWEP']['PDAT'])/2 - 127.5 + rlev\n",
    "    start_frq = _dict['fields']['SWEP']['FSTA']+ _dict['fields']['SWEP']['FSAM']/1000000000\n",
    "    stop_frq = _dict['fields']['SWEP']['FSTP']+ _dict['fields']['SWEP']['FSPM']/1000000000\n",
    "    timestamp = _dict['fields']['SWEP']['UTIM'] + _dict['fields']['SWEP']['NANO']/1000000000\n",
    "    samp = _dict['fields']['SWEP']['SAMP']\n",
    "    rbw = _dict['fields']['SWEP']['RESB']\n",
    "    freqs=np.linspace(start_frq,stop_frq,samp)\n",
    "    return xr.DataArray.from_dict({\n",
    "        \"coords\": {\n",
    "        \"freq\": {\"dims\": \"freq\", \"data\": freqs, \"attrs\": {\"units\": \"hz\"}},\n",
    "        \"time\": {\"dims\": \"time\", \"data\": [timestamp], \"attrs\": {\"units\": \"s\"}}\n",
    "        },\n",
    "        'attrs': {'source_id': source_id,'rlev': rlev, 'start_frq': start_frq, 'stop_frq': stop_frq, 'samp': samp, 'rbw': rbw},\n",
    "        'data': [pdat],\n",
    "        \"dims\": (\"time\",\"freq\"),\n",
    "        'name': 'power'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee97664-5e7c-40e3-9520-2cdb2e8ce6b2",
   "metadata": {},
   "source": [
    "use the slices to convert to xarrays and save to a dictionary then combine the ones with the same source and start stop frequency to a single xarray and save the zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111fada-5ae2-4599-9042-603c65750658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "scans = []\n",
    "data_dict = {}\n",
    "\n",
    "for s in slices:\n",
    "    start, stop = s\n",
    "    arr = dict_to_xr(tup_to_dict(*decode_packet(data[start:stop])))\n",
    "    source = arr.attrs['source_id']\n",
    "    start_frq = arr.attrs['start_frq']\n",
    "    stop_frq = arr.attrs['stop_frq']\n",
    "    scan_name = f'{source}-{start_frq}_{stop_frq}'\n",
    "    if scan_name in scans:\n",
    "        data_dict[scan_name].append(arr)\n",
    "    else:\n",
    "        scans.append(scan_name)\n",
    "        data_dict[scan_name] = [arr]\n",
    "for scan in scans:\n",
    "    combined = xr.combine_by_coords(data_dict[scan], combine_attrs = \"drop_conflicts\")\n",
    "    store = zarr.ZipStore(f'{scan}.zip', mode='w')\n",
    "    combined.to_zarr(store=store)\n",
    "stop_time = time.time()\n",
    "print(stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f912ae7-091a-4963-a990-7bff5ce44e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "zips = []\n",
    "files = os.listdir()\n",
    "for file in files:\n",
    "    if file[-3:] == 'zip':\n",
    "        zips.append(file)\n",
    "zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022154b-7334-43b4-9af0-10b875324bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = zips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13534cd5-9b64-4d46-aab4-71fca6de8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.open_zarr(zips[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102c75f-d213-4c85-a47b-2af93fe1bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "hv.Image(xr_data).opts(cmap='jet', clim=(-100,-75), width=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
